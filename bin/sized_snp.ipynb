{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Program to down-size option chains\n",
    "Date: 24-June-2019\n",
    "Rev: 1.0\n",
    "Time taken to execute fully: 1 hour and 15 mins\"\"\"\n",
    "\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "# # from json\n",
    "a = assign_var('common') + assign_var('snp')\n",
    "for v in a:\n",
    "    exec(v)\n",
    "\n",
    "# ib = get_connected('snp', 'live')\n",
    "df_chains = pd.read_pickle(fspath+'snp_chains.pkl')\n",
    "df_ohlcs = pd.read_pickle(fspath+'ohlcs.pkl')\n",
    "\n",
    "# log to size_chains.log\n",
    "with open(logpath+'size_chains.log', 'w'):\n",
    "    pass # clear the run log\n",
    "util.logToFile(logpath+'size_chains.log')\n",
    "\n",
    "#... Remove chains not meeting put and call std filter\n",
    "\n",
    "# get dte and remove those greater than maxdte\n",
    "df_chains = df_chains.assign(dte=df_chains.expiry.apply(get_dte))                    \n",
    "df_chains = df_chains[df_chains.dte <= maxdte]\n",
    "\n",
    "# generate std dataframe\n",
    "df = df_ohlcs[['symbol', 'stDev']]  # lookup dataframe\n",
    "df = df.assign(dte=df.groupby('symbol').cumcount()) # get the cumulative count for location as dte\n",
    "df.set_index(['symbol', 'dte'])\n",
    "\n",
    "df1 = df_chains[['symbol', 'dte']]  # data to be looked at\n",
    "df2 = df1.drop_duplicates()  # remove duplicates\n",
    "\n",
    "df_std = df2.set_index(['symbol', 'dte']).join(df.set_index(['symbol', 'dte']))\n",
    "\n",
    "# join to get std in chains\n",
    "df_chainstd = df_chains.set_index(['symbol', 'dte']).join(df_std).reset_index()\n",
    "\n",
    "und_contracts = [Stock(symbol, exchange=exchange, currency='USD') for symbol in df_chainstd.symbol.unique()]\n",
    "with get_connected('snp', 'live') as ib:\n",
    "    und_quals = ib.qualifyContracts(*und_contracts)\n",
    "    tickers = ib.reqTickers(*und_quals)\n",
    "\n",
    "uprice_dict = {u.contract.conId: u.marketPrice() for u in tickers}\n",
    "\n",
    "df_chainstd = df_chainstd.assign(undPrice=df_chainstd.undId.astype('int').map(uprice_dict))\n",
    "\n",
    "# make puts and calls dataframe with std filter\n",
    "df_puts = df_chainstd[df_chainstd.strike < (df_chainstd.undPrice-(df_chainstd.stDev*putstdmult))]\n",
    "df_puts = df_puts.assign(right = 'P')\n",
    "\n",
    "df_calls = df_chainstd[df_chainstd.strike > (df_chainstd.undPrice+(df_chainstd.stDev*callstdmult))]\n",
    "df_calls = df_calls.assign(right = 'C')\n",
    "\n",
    "df_opt = pd.concat([df_puts, df_calls], sort=False).reset_index(drop=True)\n",
    "\n",
    "# get lo52 and hi52\n",
    "df_opt = df_opt.set_index('symbol').join(df_ohlcs.groupby('symbol')\n",
    "                                         .close.agg(['min', 'max'])\n",
    "                                         .rename(columns={'min': 'lo52', 'max': 'hi52'})).reset_index()\n",
    "\n",
    "# make (df and dte) tuple for fallrise\n",
    "tup4fr = [(df_ohlcs[df_ohlcs.symbol == s.symbol], s.dte) \n",
    "          for s in df_opt[['symbol', 'dte']].drop_duplicates().itertuples()]\n",
    "\n",
    "# get the fallrise and put it into a dataframe\n",
    "fr = [fallrise(*t) for t in tup4fr]\n",
    "df_fr = pd.DataFrame(fr, columns=['symbol', 'dte', 'fall', 'rise' ])\n",
    "\n",
    "# merge with df_opt\n",
    "df_opt = pd.merge(df_opt, df_fr, on=['symbol', 'dte'])\n",
    "\n",
    "# make reference strikes from fall_rise\n",
    "df_opt = df_opt.assign(strikeRef = np.where(df_opt.right == 'P', \n",
    "                                            df_opt.undPrice-df_opt.fall, \n",
    "                                            df_opt.undPrice+df_opt.rise))\n",
    "\n",
    "# get the strikes closest to the reference strikes\n",
    "df_opt = df_opt.groupby(['symbol', 'dte']) \\\n",
    "                         .apply(lambda g: g.iloc[abs(g.strike-g.strikeRef) \\\n",
    "                                                 .argsort()[:nBand]])\n",
    "\n",
    "df_opt = df_opt.set_index('symbol').reset_index()\n",
    "\n",
    "# get the option contracts\n",
    "\n",
    "opt_list = [Option(i.symbol, i.expiry, i.strike, i.right, 'SMART') for i in df_opt[['symbol', 'expiry', 'strike', 'right']].itertuples()]\n",
    "\n",
    "util.logToFile(logpath+'test.log') # prevents unknown contract errors in console\n",
    "\n",
    "opt_contracts = []\n",
    "with get_connected('snp', 'live') as ib:\n",
    "    print(\"Qualifying option contracts ...(2 to 8 mins)\")\n",
    "    opt_contracts = ib.qualifyContracts(*opt_list)\n",
    "\n",
    "# integrate optId with df_opt and remove df_opt without optId\n",
    "dfq = util.df(opt_contracts).iloc[:, 1:6]\n",
    "dfq.columns=['optId', 'symbol', 'expiry', 'strike', 'right'] # rename columns\n",
    "df_opt=df_opt.merge(dfq, on=['symbol', 'expiry', 'strike', 'right'], how='left')\n",
    "df_opt = df_opt[~df_opt.optId.isnull()]\n",
    "df_opt = df_opt.assign(optId=df_opt.optId.astype('int'))\n",
    "\n",
    "# get the option prices\n",
    "with get_connected('snp', 'live') as ib:\n",
    "    ticker = ib.reqTickers(*opt_contracts)\n",
    "\n",
    "df_prices = pd.DataFrame({t.contract.conId: {'bid':t.bid, 'ask':t.ask, 'close':t.close} for t in ticker}).T\n",
    "\n",
    "# ...get margins\n",
    "\n",
    "# prepare the lots\n",
    "idlot_idx = df_opt[['optId', 'lot']].set_index('optId').to_dict('index')\n",
    "idlot = {k: Order(action='SELL', orderType='MKT', totalQuantity=v['lot'], whatIf=True) for k, v in idlot_idx.items()}\n",
    "\n",
    "co = [(c, idlot[c.conId]) for c in opt_contracts]\n",
    "\n",
    "# co = co[:110]  # DATA LIMITER !!!\n",
    "coblks = [co[i: i+blk] for i in range(0, len(co), blk)]\n",
    "\n",
    "m = {} # empty dictionary to collect outputs of getMarginAsync\n",
    "with get_connected('snp', 'live') as ib:\n",
    "    async def coro(coblk):\n",
    "        with tqdm(total=len(coblk), file=sys.stdout, unit=' symexpiry') as tqm:\n",
    "            for c, o in coblk:\n",
    "                tqm.set_description(f\"IBKR margins for  {c.localSymbol.ljust(22)}\")\n",
    "                m.update(await getMarginAsync(ib, c, o))\n",
    "                tqm.update(1)\n",
    "            return m\n",
    "\n",
    "# run co-routines to get the margins        \n",
    "for coblk in coblks:\n",
    "    with get_connected('snp', 'live') as ib:\n",
    "        asyncio.run(coro(coblk))\n",
    "\n",
    "# put margins to df_opt\n",
    "m_dict = {i: float(j.initMarginChange) for i, j in {k: v for k, v in m.items() if v}.items() if str(j) != 'nan'}\n",
    "\n",
    "df_margin = pd.DataFrame.from_dict(m_dict, orient='index', columns=['margin'])\n",
    "\n",
    "df_opt = df_opt.set_index('optId').join(df_prices).join(df_margin).reset_index()\n",
    "\n",
    "df_opt = grp_opts(df_opt.assign(rom=df_opt.close/df_opt.margin*365/df_opt.dte*df_opt.lot))\n",
    "\n",
    "df_opt.to_pickle(fspath+'sized.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code for snp sized\n",
    "\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "# from json (for logpath)\n",
    "a = assign_var('snp')\n",
    "for v in a:\n",
    "    exec(v)\n",
    "\n",
    "from chains_snp import *\n",
    "from ohlcs import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #... check for snp_chains.pkl\n",
    "    if path.isfile(fspath+'snp_chains.pkl'):\n",
    "        df_chains = pd.read_pickle(fspath+'snp_chains.pkl')\n",
    "    else:\n",
    "        with get_connected('snp', 'live') as ib:\n",
    "            df_chains = get_chains(ib)  # get snp purely from a list. Not from snp website\n",
    "\n",
    "#     df_chains = df_chains[df_chains.symbol.isin(['BANKNIFTY', 'PNB'])]  # DATA LIMITER!!!\n",
    "\n",
    "    if path.isfile(fspath+'ohlcs.pkl'):\n",
    "        df_ohlcs = pd.read_pickle(fspath+'ohlcs.pkl')\n",
    "        \n",
    "    else:\n",
    "        id_sym = df_chains.set_index('undId').symbol.to_dict()\n",
    "    \n",
    "    with get_connected('snp', 'live') as ib:\n",
    "        df_ohlcs = ohlcs(ib, id_sym, fspath, logpath)\n",
    "\n",
    "    df_ohlcs.to_pickle(fspath+'ohlcs.pkl')\n",
    "    \n",
    "    market = 'snp'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sized_nse import \n",
    "with get_connected('nse', 'live') as ib:\n",
    "    df_opt = sized_nse(ib, df_chains, df_ohlcs, market=market)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sized_nse import *\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "market = 'nse'\n",
    "\n",
    "init_variables(market)\n",
    "\n",
    "# # # from json\n",
    "# a = assign_var('common') + assign_var(market)\n",
    "# for v in a:\n",
    "#     exec(v)\n",
    "\n",
    "df_chains = pd.read_pickle(fspath+market+'_chains.pkl')\n",
    "df_ohlcs = pd.read_pickle(fspath+'ohlcs.pkl')\n",
    "\n",
    "with get_connected('nse', 'live') as ib:\n",
    "    df_opt = sized_nse(ib, df_chains, df_ohlcs, market='nse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z_helper import *\n",
    "market = 'nse'\n",
    "\n",
    "x = init_variables(market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec('global '+x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# test code for NSE\n",
    "\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "# from json (for logpath)\n",
    "a = assign_var('nse')\n",
    "for v in a:\n",
    "    exec(v)\n",
    "\n",
    "from chains_nse import *\n",
    "from ohlcs import *\n",
    "from sized import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #... check for nse_chains.pkl\n",
    "    if path.isfile(fspath+'nse_chains.pkl'):\n",
    "        df_chains = pd.read_pickle(fspath+'nse_chains.pkl')\n",
    "    else:\n",
    "        df_chains = get_chains(nseweb=False)  # get nse purely from a list. Not from nse website\n",
    "\n",
    "#     df_chains = df_chains[df_chains.symbol.isin(['BANKNIFTY', 'PNB'])]  # DATA LIMITER!!!\n",
    "\n",
    "    id_sym = df_chains.set_index('undId').symbol.to_dict()\n",
    "\n",
    "    if path.isfile(fspath+'ohlcs.pkl'):\n",
    "        df_ohlcs = pd.read_pickle(fspath+'ohlcs.pkl')\n",
    "    else:\n",
    "        with get_connected('nse', 'live') as ib:\n",
    "            df_ohlcs = ohlcs(ib, id_sym, fspath, logpath)\n",
    "\n",
    "    #... run size_chains\n",
    "    with get_connected('nse', 'live') as ib:\n",
    "        df_target = sized_nse(ib, df_chains=df_chains, df_ohlcs=df_ohlcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_target\n",
    "for v in a:\n",
    "    exec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = 'nse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = assign_var('common') + assign_var(market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in a:\n",
    "    exec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_connected('nse', 'live') as ib:\n",
    "    size_chains(ib, df_chains, df_ohlcs, market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt[mask].sort_values('rom', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'nse'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
