{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohlcs.py\n",
    "\"\"\"Program that generates ohlcs\n",
    "Date: 23-June-2019\n",
    "Ver: 1.0\n",
    "Time taken: \n",
    " - all from IBKR: 8 mins\n",
    " - from NSE Web:\n",
    "\"\"\"\n",
    "from z_helper import *  # needed for util\n",
    "\n",
    "def ohlcs(ib, id_sym, fspath, logpath):\n",
    "    '''Get ohlcs with stDev (8 mins)\n",
    "    Args:\n",
    "        (ib) as connection object\n",
    "        (id_sym) as {undId: 'symbol'} dictionary\n",
    "        (logpath) as string for path for lots\n",
    "        (fspath) as string for path of pickles\n",
    "    Returns:\n",
    "        ohlcs dataframe with stDev'''\n",
    "\n",
    "    with open(logpath+'ohlc.log', 'w'):\n",
    "        pass # clear the run log\n",
    "\n",
    "    util.logToFile(logpath+'ohlc.log')\n",
    "\n",
    "    ohlcs = []\n",
    "    with tqdm(total= len(id_sym), file=sys.stdout, unit= 'symbol') as tqh:\n",
    "        for k, v in id_sym.items():\n",
    "            tqh.set_description(f\"Getting OHLC hist frm IBKR for {v.ljust(9)}\")\n",
    "            ohlcs.append(catch(lambda:do_hist(ib, k, fspath)))\n",
    "            tqh.update(1)\n",
    "\n",
    "    # Remove nan from ohlcs list\n",
    "    li = [o for o in ohlcs if str(o) != 'nan']\n",
    "    \n",
    "    df_ohlcs = pd.concat(li).reset_index(drop=True)\n",
    "    \n",
    "    return df_ohlcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code for NSE ohlcs\n",
    "\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "# from json (for logpath)\n",
    "a = assign_var('nse')\n",
    "for v in a:\n",
    "    exec(v)\n",
    "\n",
    "from chains_nse import *\n",
    "from ohlcs import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #... check for chains_nse.pkl\n",
    "    if path.isfile(fspath+'chains_nse.pkl'):\n",
    "        df_chains = pd.read_pickle(fspath+'chains_nse.pkl')\n",
    "    else:\n",
    "        df_chains = get_chains(nseweb=False)  # get nse purely from a list. Not from nse website\n",
    "\n",
    "#     df_chains = df_chains[df_chains.symbol.isin(['BANKNIFTY', 'PNB'])]  # DATA LIMITER!!!\n",
    "\n",
    "    id_sym = df_chains.set_index('undId').symbol.to_dict()\n",
    "    \n",
    "    with get_connected('nse', 'live') as ib:\n",
    "        df_ohlcs = ohlcs(ib, id_sym, fspath, logpath)\n",
    "\n",
    "df_ohlcs.to_pickle(fspath+'ohlcs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting strikes & expiries for NVDA     : 100%|█████████████████████████████████| 91/91 [00:06<00:00, 13.06 contract/s]\n",
      "Getting OHLC hist frm IBKR for XOM      : 100%|████████████████████████████████████| 91/91 [03:13<00:00,  1.11symbol/s]\n"
     ]
    }
   ],
   "source": [
    "# test code for SNP ohlcs\n",
    "\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "# from json (for logpath)\n",
    "a = assign_var('snp')\n",
    "for v in a:\n",
    "    exec(v)\n",
    "\n",
    "from chains_snp import *\n",
    "from ohlcs import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #... check for chains_snp.pkl\n",
    "    if path.isfile(fspath+'chains_snp.pkl'):\n",
    "        df_chains = pd.read_pickle(fspath+'chains_snp.pkl')\n",
    "    else:\n",
    "        with get_connected('snp', 'live') as ib:\n",
    "            df_chains = get_chains(ib)  # get snp purely from a list. Not from snp website\n",
    "\n",
    "#     df_chains = df_chains[df_chains.symbol.isin(['BANKNIFTY', 'PNB'])]  # DATA LIMITER!!!\n",
    "\n",
    "    id_sym = df_chains.set_index('undId').symbol.to_dict()\n",
    "    \n",
    "    with get_connected('snp', 'live') as ib:\n",
    "        df_ohlcs = ohlcs(ib, id_sym, fspath, logpath)\n",
    "\n",
    "df_ohlcs.to_pickle(fspath+'ohlcs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the ohlc pickles from pickled files (manually)\n",
    "ohlc_pkls = [f for f in listdir(fspath) if (f[-8:] == 'ohlc.pkl')]\n",
    "df = pd.concat([pd.read_pickle(fspath+o) for o in ohlc_pkls]).reset_index(drop=True)\n",
    "df.to_pickle(fspath+'ohlcs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
