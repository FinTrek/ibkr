{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do:\n",
    "* Make it user interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the market <'snp'> | <'nse'>\n",
    "market = 'nse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from z_helper import *\n",
    "\n",
    "util.startLoop()\n",
    "\n",
    "ib = get_connected(market, 'live')\n",
    "\n",
    "# from json\n",
    "a = assign_var(market) + assign_var('common')\n",
    "for v in a:\n",
    "    exec(v)\n",
    "    \n",
    "jup_disp_adjust() # adjust jupyter's display\n",
    "\n",
    "with open(logpath+'target.log', 'w'):\n",
    "    pass # clear the run log\n",
    "\n",
    "util.logToFile(logpath+'target.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_all_data(market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#...Get the chains\n",
    "\n",
    "if market == 'snp': # code for snp only - 35 mins\n",
    "\n",
    "    # Download cboe weeklies to a dataframe\n",
    "    dls = \"http://www.cboe.com/publish/weelkysmf/weeklysmf.xls\"\n",
    "\n",
    "    # read from row no 11, dropna and reset index\n",
    "    df_cboe = pd.read_excel(dls, header=12, \n",
    "                            usecols=[0,2,3]).loc[11:, :]\\\n",
    "                            .dropna(axis=0)\\\n",
    "                            .reset_index(drop=True)\n",
    "\n",
    "    # remove column names white-spaces and remap to IBKR\n",
    "    df_cboe.columns = df_cboe.columns.str.replace(' ', '')\n",
    "\n",
    "    # remove '/' for IBKR\n",
    "    df_cboe.Ticker = df_cboe.Ticker.str.replace('/', ' ', regex=False)\n",
    "\n",
    "    snp100 = list(pd.read_html('https://en.wikipedia.org/wiki/S%26P_100', \n",
    "                               header=0, match='Symbol')[0].loc[:, 'Symbol'])\n",
    "    snp100 = [s.replace('.', ' ') if '.' in s else s  for s in snp100] # without dot in symbol\n",
    "\n",
    "    # remove equities not in snp100\n",
    "    df_symbols = df_cboe[~((df_cboe.ProductType == 'Equity') & ~df_cboe.Ticker.isin(snp100))]\n",
    "    \n",
    "    # rename Ticker to symbols\n",
    "    df_symbols = df_symbols.rename({'Ticker': 'symbol'}, axis=1)\n",
    "    \n",
    "    # add in the lots\n",
    "    df_symbols = df_symbols.assign(lot=100)\n",
    "\n",
    "    # !!! DATA LIMITER !!! Get 8 symbols. 5 Equities and 3 ETFs\n",
    "    # df_symbols = pd.concat([df_symbols[df_symbols.ProductType == 'Equity'].head(7), df_symbols.head(3)]) # !!! DATA LIMITER !!!\n",
    "    \n",
    "    instruments = [Stock(s, exchange, currency) for s in list(df_symbols.symbol)]\n",
    "    \n",
    "else: # code for NSE - 15 mins\n",
    "    \n",
    "    # extract from tradeplusonline\n",
    "    tp = pd.read_html('https://www.tradeplusonline.com/Equity-Futures-Margin-Calculator.aspx')\n",
    "    df_tp = tp[1][2:].iloc[:, :3].reset_index(drop=True)\n",
    "    df_tp.columns=['symbol', 'lot', 'undPrice']\n",
    "    df_tp = df_tp.apply(pd.to_numeric, errors='ignore') # convert lot and undPrice to numeric\n",
    "\n",
    "    # convert symbols - friendly to IBKR\n",
    "    df_tp = df_tp.assign(symbol=df_tp.symbol.str.slice(0,9))\n",
    "    ntoi = {'M&M': 'MM', 'M&MFIN': 'MMFIN', 'L&TFH': 'LTFH', 'NIFTY': 'NIFTY50'}\n",
    "    df_tp.symbol = df_tp.symbol.replace(ntoi)\n",
    "    df_symbols = df_tp\n",
    "    \n",
    "    # set the types for indexes as IND\n",
    "    ix_symbols = ['NIFTY50', 'BANKNIFTY', 'NIFTYIT']\n",
    "    \n",
    "    # !!! DATA LIMITER !!! Get 4 symbols. 2 Equities and 2 Indexes\n",
    "#     df_symbols = pd.concat([df_symbols[:2], df_symbols[df_symbols.symbol.isin(ix_symbols[:2])]]).reset_index(drop=True)\n",
    "\n",
    "    # build the underlying contracts\n",
    "    scrips = list(df_symbols.symbol)\n",
    "    \n",
    "    instruments = [Index(symbol=s, exchange=exchange) if s in ix_symbols else Stock(symbol=s, exchange=exchange) for s in scrips]\n",
    "\n",
    "# ... Build chains df with undPrice\n",
    "# qualify contracts (asyncio)\n",
    "q_task = []\n",
    "async def qual_coro(instruments):\n",
    "    '''Coroutines with waits for qualification of instruments\n",
    "    Arg: (instruments) as list of Stock(symbol, exchange, currency)\n",
    "    Returns: awaits of qualifyContractsAsync(s)'''\n",
    "    for s in instruments:\n",
    "        q_task.append(ib.qualifyContractsAsync(s))\n",
    "    return await asyncio.gather(*q_task)\n",
    "\n",
    "uct = asyncio.run(qual_coro(instruments))\n",
    "\n",
    "und_contracts = [b for a in uct for b in a]\n",
    "\n",
    "id_sym = {u.conId: u.symbol for u in und_contracts}\n",
    "print(\"\\nCompleted qualifying underlyings\\n\")\n",
    "\n",
    "# get tickers and undPrice (asyncio)\n",
    "ut = [] # empty tickers\n",
    "\n",
    "und_blks = [und_contracts[i: i+blk] for i in range(0, len(und_contracts), blk)]\n",
    "\n",
    "for unds in und_blks:\n",
    "    reqt = ib.reqTickersAsync(*unds)\n",
    "    ut.append(ib.run(asyncio.wait_for(reqt, 20)))\n",
    "und_ticks = [b for a in ut for b in a]\n",
    "\n",
    "undPrice = {u.contract.conId: u.marketPrice() for u in und_ticks}\n",
    "print(\"\\nCompleted getting underlying prices\\n\")\n",
    "\n",
    "# get the chains\n",
    "\n",
    "ch_task = []\n",
    "async def chains_coro(und_contracts):\n",
    "    '''Get the chains for underlyings\n",
    "    Arg: (und_contracts) as a list\n",
    "    Returns: awaits of reqSecDefOptPramsAsyncs'''\n",
    "    for c in und_contracts:\n",
    "        ch_task.append(ib.reqSecDefOptParamsAsync(underlyingSymbol=c.symbol, futFopExchange='', \n",
    "                             underlyingConId=c.conId, underlyingSecType=c.secType))\n",
    "    return await asyncio.gather(*ch_task)\n",
    "\n",
    "ch = asyncio.run(chains_coro(und_contracts))\n",
    "\n",
    "chs = [b for a in ch for b in a]\n",
    "\n",
    "chains = {c.underlyingConId: c for c in chs}\n",
    "\n",
    "sek = {b for a in [list(product([k], m.expirations, m.strikes)) for k, m in chains.items()] for b in a}\n",
    "\n",
    "df_chains1 = pd.DataFrame(list(sek), columns=['undId', 'expiry', 'strike'])\n",
    "df_chains1 = df_chains1.assign(undId=df_chains1.undId.astype('int32'))\n",
    "\n",
    "df_chains1 = df_chains1.assign(symbol = df_chains1.undId.map(id_sym), \n",
    "                             undPrice = df_chains1.undId.map(undPrice))\n",
    "\n",
    "if market == 'nse':  # code for NSE only\n",
    "    # add expiryM to get lots from get_nse_lots()\n",
    "    df_chains1 = df_chains1.assign(expiryM=pd.to_datetime(df_chains1.expiry).dt.strftime('%Y-%m'))\n",
    "    # update lots of NSE equities\n",
    "    lots = get_nse_lots()\n",
    "    lots = lots.assign(expiryM=lots.expiryM.astype('str'))\n",
    "    lots = lots[['symbol', 'expiryM', 'lot']].set_index(['symbol', 'expiryM'])\n",
    "\n",
    "    chz = df_chains1.set_index(['symbol', 'expiryM'])\n",
    "\n",
    "    df_chains = chz.join(lots).reset_index().drop('expiryM', 1)\n",
    "\n",
    "    # For those with nan - forget the expiry!\n",
    "    df_symlot = lots.reset_index().drop('expiryM', 1).drop_duplicates()\n",
    "    symlot = dict(zip(df_symlot.symbol, df_symlot.lot))\n",
    "\n",
    "    df_chains = df_chains.assign(lot=df_chains.symbol.map(symlot).fillna(df_chains.lot))\n",
    "    \n",
    "else: # For SNP\n",
    "    df_chains = df_chains1.assign(lot=100)\n",
    "\n",
    "df_chains = df_chains.sort_values(['symbol', 'expiry', 'strike'])\n",
    "df_chains = df_chains[['symbol', 'undId', 'expiry', 'strike', 'undPrice', 'lot']].reset_index(drop=True)\n",
    "df_chains = df_chains.assign(dte=df_chains.expiry.apply(get_dte))\n",
    "\n",
    "df_chains.to_pickle(fspath+'chains.pkl')\n",
    "\n",
    "print(\"\\nCompleted getting chains\\n\")\n",
    "\n",
    "#... Get the OHLCs (asyncio)\n",
    "\n",
    "async def ohlc_coro(und_contracts):\n",
    "    \n",
    "    ohlc_task = []\n",
    "    \n",
    "    # build the tasks\n",
    "    for qc in und_contracts:\n",
    "        ohlc_task.append(ib.reqHistoricalDataAsync(contract=qc, endDateTime='', \n",
    "                                        durationStr='365 D', barSizeSetting='1 day',  \n",
    "                                                    whatToShow='Trades', useRTH=True))\n",
    "    return await asyncio.gather(*ohlc_task)\n",
    "\n",
    "# make blocks of tasks\n",
    "ohlcs = []\n",
    "\n",
    "for unds in und_blks:\n",
    "    ohlcs = ohlcs + asyncio.run(ohlc_coro(unds))\n",
    "\n",
    "# make the ohlc dataframe\n",
    "df_ohlc = pd.DataFrame()\n",
    "for i, o in enumerate(ohlcs):\n",
    "    df = util.df(o)\n",
    "    if not o:\n",
    "        print(f'{und_contracts[i].symbol} ohlc is empty')\n",
    "    else:\n",
    "        df_ohlc = df_ohlc.append(df.assign(symbol=und_contracts[i].symbol))\n",
    "        \n",
    "#... compute the standard deviations\n",
    "df_ohlc = df_ohlc.assign(date=pd.to_datetime(df_ohlc.date, format='%Y-%m-%d'))\n",
    "\n",
    "grp1 = df_ohlc.groupby('symbol')\n",
    "grp2 = grp1.apply(lambda df: df.sort_values('date', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "df_ohlcsd = grp2.groupby('symbol').apply(lambda df: df.assign(stDev=df.close.expanding(1).std(ddof=0))).reset_index(drop=True)\n",
    "\n",
    "df_ohlcsd.to_pickle(fspath+'ohlcs.pkl')\n",
    "\n",
    "print(\"\\nCompleted getting ohlcs\\n\")\n",
    "\n",
    "# ... Size the chains\n",
    "\n",
    "# replace dte with 1 for dte <= 0\n",
    "df_chains.loc[df_chains.dte <=0,  'dte'] = 1\n",
    "df1 = df_chains[df_chains.dte <= maxdte]\n",
    "\n",
    "# assign right\n",
    "df1 = df1.assign(right=np.where(df1.strike >= df1.undPrice, 'C', 'P'))\n",
    "\n",
    "# generate std dataframe\n",
    "dfo = df_ohlcsd[['symbol', 'stDev']]  # lookup dataframe\n",
    "dfo = dfo.assign(dte=dfo.groupby('symbol').cumcount()) # get the cumulative count for location as dte\n",
    "dfo.set_index(['symbol', 'dte'])\n",
    "\n",
    "dfd = df1[['symbol', 'dte']]  # data to be looked at\n",
    "dfd = dfd.drop_duplicates()  # remove duplicates\n",
    "\n",
    "df_std = dfd.set_index(['symbol', 'dte']).join(dfo.set_index(['symbol', 'dte']))\n",
    "\n",
    "# join to get std in chains\n",
    "df2 = df1.set_index(['symbol', 'dte']).join(df_std).reset_index()\n",
    "\n",
    "# remove the calls and puts near strike price\n",
    "c_mask = (df2.right == 'C') & (df2.strike > df2.undPrice + callstdmult*df2.stDev)\n",
    "p_mask = (df2.right == 'P') & (df2.strike < df2.undPrice - putstdmult*df2.stDev)\n",
    "df3 = df2[c_mask | p_mask].reset_index(drop=True)\n",
    "\n",
    "# make (df and dte) tuple for fallrise\n",
    "tup4fr = [(df_ohlc[df_ohlc.symbol == s.symbol], s.dte) \n",
    "          for s in df3[['symbol', 'dte']].drop_duplicates().itertuples()]\n",
    "\n",
    "# get the fallrise and put it into a dataframe\n",
    "fr = [fallrise(*t) for t in tup4fr]\n",
    "df_fr = pd.DataFrame(fr, columns=['symbol', 'dte', 'fall', 'rise' ])\n",
    "\n",
    "# merge with options df\n",
    "df3 = pd.merge(df3, df_fr, on=['symbol', 'dte'])\n",
    "\n",
    "# make reference strikes from fall_rise\n",
    "df3 = df3.assign(strikeRef = np.where(df3.right == 'P', \n",
    "                                            df3.undPrice-df3.fall, \n",
    "                                            df3.undPrice+df3.rise))\n",
    "# get lo52 and hi52\n",
    "df3 = df3.set_index('symbol').join(df_ohlcsd.groupby('symbol')\n",
    "                                         .close.agg(['min', 'max'])\n",
    "                                         .rename(columns={'min': 'lo52', 'max': 'hi52'})).reset_index()\n",
    "\n",
    "# ...Filter # 1: Top nband for Puts and Calls > mindte\n",
    "# building SELLS for further expiries\n",
    "df4 = df3[df3.dte >= mindte]\n",
    "\n",
    "gb = df4.groupby(['right'])\n",
    "\n",
    "if 'C' in [k for k in gb.indices]:\n",
    "    df_calls = gb.get_group('C').reset_index(drop=True).sort_values(['symbol', 'dte', 'strike'], ascending=[True, True, True])\n",
    "    df_calls = df_calls.groupby(['symbol', 'dte']).head(nBand)\n",
    "else:\n",
    "    df_calls = pd.DataFrame([])\n",
    "\n",
    "if 'P' in [k for k in gb.indices]:\n",
    "    df_puts = gb.get_group('P').reset_index(drop=True).sort_values(['symbol', 'dte', 'strike'], ascending=[True, True, False])\n",
    "    df_puts = df_puts.groupby(['symbol', 'dte']).head(nBand)\n",
    "else:\n",
    "    df_puts =  pd.DataFrame([])\n",
    "\n",
    "df5 = pd.concat([df_puts, df_calls]).reset_index(drop=True)\n",
    "\n",
    "# ....Filter # 2: nBands with fallrise for expiries less than a week\n",
    "# building SELLS for nearer expiries with fallrise\n",
    "\n",
    "df6 = df3[df3.dte < mindte]\n",
    "\n",
    "if df6.empty: # there are no contracts below minimum dte\n",
    "    df8 = pd.DataFrame([])\n",
    "else:\n",
    "    # get the strikes closest to the reference strikes\n",
    "    df7 = df6.groupby(['symbol', 'dte'], as_index=False) \\\n",
    "             .apply(lambda g: g.iloc[abs(g.strike - g.strikeRef) \\\n",
    "             .argsort()[:nBand]]) \\\n",
    "             .reset_index(drop=True)\n",
    "\n",
    "    df8 = df7.sort_values(['symbol', 'dte', 'strike'])\n",
    "\n",
    "# make the target master\n",
    "df9 = pd.concat([df8, df5], sort=False).sort_values(['symbol', 'dte', 'strike'], \n",
    "                                                    ascending=[True, True, False]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Filter out calls that don't meet the Rise criteria in the master. These are risky\n",
    "df9 = df9[~((df9.right == 'C') & (df9.strike < df9.strikeRef))].reset_index(drop=True)\n",
    "\n",
    "print(\"\\nCompleted sizing master for target\\n\")\n",
    "\n",
    "#...Get option prices and margins\n",
    "\n",
    "# qualify the option contracts\n",
    "\n",
    "qo_task = []\n",
    "opts = [Option(i.symbol, i.expiry, i.strike, i.right, exchange) for i in df9[['symbol', 'expiry', 'strike', 'right']].itertuples()]\n",
    "\n",
    "async def qopt_coro(contracts):\n",
    "    '''Coroutines with waits for qualification of stocks\n",
    "    Arg: (contracts) as list of Stock(symbol, exchange, currency)\n",
    "    Returns: awaits of qualifyContractsAsync(s)'''\n",
    "    for c in contracts:\n",
    "        qo_task.append(ib.qualifyContractsAsync(c))\n",
    "    return await asyncio.gather(*qo_task)\n",
    "\n",
    "qual_opts = asyncio.run(qopt_coro(opts))\n",
    "\n",
    "print(\"\\nCompleted qualifying option contracts\\n\")\n",
    "\n",
    "# get tickers and optPrice (asyncio)\n",
    "\n",
    "opt_ct = [ct for q in qual_opts for ct in q if q] # remove []\n",
    "opt_blks = [opt_ct[i: i+blk] for i in range(0, len(opt_ct), blk)]\n",
    "\n",
    "ot = []\n",
    "\n",
    "for opt in opt_blks:\n",
    "    reqot = ib.reqTickersAsync(*opt)\n",
    "    ot.append(ib.run(asyncio.wait_for(reqot, 18)))\n",
    "\n",
    "opt_price = {t.contract.conId: t.marketPrice() \n",
    "             for opts in ot \n",
    "             for t in opts \n",
    "             if t.marketPrice() > -1} # cleaned nans\n",
    "\n",
    "df_opt1 = util.df(opt_ct)\n",
    "df_opt2 = df_opt1[list(df_opt1)[1:6]].rename(columns={'lastTradeDateOrContractMonth': 'expiry', 'conId': 'optId'})\n",
    "\n",
    "df_opt3 = df_opt2.assign(optPrice=df_opt2.optId.map(opt_price))\n",
    "df_opt4 = df_opt3[df_opt3.optPrice >= 0]\n",
    "\n",
    "df_opt5 = pd.merge(df_opt4, df9, on=['symbol', 'expiry', 'strike', 'right'])\n",
    "\n",
    "print(\"\\nCompleted getting option prices\\n\")\n",
    "\n",
    "#... Get the margins\n",
    "\n",
    "# build options and orders\n",
    "mgn_opts = list(df_opt5.optId.map({c.conId: c for c in opt_ct}))\n",
    "\n",
    "if market == 'snp':\n",
    "    mgn_ords = [Order(action='SELL', orderType='MKT', totalQuantity=1, whatIf=True) for r in df_opt5.lot]\n",
    "else:\n",
    "    mgn_ords = [Order(action='SELL', orderType='MKT', totalQuantity=r, whatIf=True) for r in df_opt5.lot]\n",
    "\n",
    "co = list(zip(mgn_opts, mgn_ords))\n",
    "\n",
    "task = []\n",
    "async def margin_coro(co):   \n",
    "    for c in co:\n",
    "        task.append(ib.whatIfOrderAsync(*c))\n",
    "    return await asyncio.gather(*task)\n",
    "\n",
    "margins = asyncio.run(margin_coro(co))\n",
    "\n",
    "# market is checked to weed out wierd commissions. NSE has commission, while SNP has maxCommission!\n",
    "if market == 'nse':\n",
    "    df_opt6 = df_opt5.assign(margin=[catch(lambda: float(m.initMarginChange)) for m in margins], \n",
    "                       comm=[catch(lambda: float(m.commission)) for m in margins])\n",
    "else:\n",
    "    df_opt6 = df_opt5.assign(margin=[catch(lambda: float(m.initMarginChange)) for m in margins], \n",
    "                       comm=[catch(lambda: float(m.maxCommission)) for m in margins])    \n",
    "\n",
    "df_opt7 = df_opt6[df_opt6.margin < 1.7e7] # remove too high margins\n",
    "\n",
    "df_opt8 = df_opt7.assign(PoP=[erf(i/sqrt(2.0)) for i in abs(df_opt7.strike-df_opt7.undPrice)/df_opt7.stDev],\n",
    "                        RoM = abs((df_opt7.optPrice*df_opt7.lot-df_opt7.comm)/df_opt7.margin*365/df_opt7.dte))\n",
    "\n",
    "# make reference strikes from fall_rise\n",
    "df_opt9 = df_opt8.assign(strikeRef = np.where(df_opt8.right == 'P', \n",
    "                                            df_opt8.undPrice-df_opt8.fall, \n",
    "                                            df_opt8.undPrice+df_opt8.rise))\n",
    "\n",
    "df_opt9.to_pickle(fspath+'opts.pkl')\n",
    "\n",
    "print(\"\\nCompleted getting margins, computing RoM and PoP and getting fallrise, hilo52\\n\")\n",
    "\n",
    "#... Make the targets, Sells and Buys\n",
    "\n",
    "#... From local pickles for action\n",
    "\n",
    "df_chains = pd.read_pickle(fspath+'chains.pkl')\n",
    "df_opt9 = pd.read_pickle(fspath+'opts.pkl')\n",
    "\n",
    "# From Portfolio get the remaining quantitites\n",
    "p = util.df(ib.portfolio()) # portfolio table\n",
    "\n",
    "# extract option contract info from portfolio table\n",
    "if p is not None:  # there are some contracts in the portfolio\n",
    "    dfp = pd.concat([p, util.df([c for c in p.contract])[util.df([c for c in p.contract]).columns[:7]]], axis=1).iloc[:, 1:]\n",
    "    dfp = dfp.rename(columns={'lastTradeDateOrContractMonth': 'expiry'})\n",
    "\n",
    "    # extract the options\n",
    "    dfpo = dfp[dfp.secType == 'OPT']\n",
    "\n",
    "    # get unique symbol, lot and underlying\n",
    "    df_lu = df_chains[['symbol', 'lot', 'undId', 'undPrice']].groupby('symbol').first()\n",
    "\n",
    "    # integrate the options with lot and underlying\n",
    "    dfp1 = dfpo.set_index('symbol').join(df_lu).reset_index()\n",
    "\n",
    "    # correct the positions for nse\n",
    "    if exchange == 'NSE':\n",
    "        dfp1 = dfp1.assign(position=dfp1.position/dfp1.lot)\n",
    "\n",
    "    # get the total position for options\n",
    "    dfp2 = dfp1[['symbol', 'position']].groupby('symbol').sum()\n",
    "    \n",
    "    # Get Stock positions\n",
    "    dfs1 = p[p.contract.apply(lambda x: str(x)).str.contains('Stock')]\n",
    "    if not dfs1.empty:\n",
    "        dfs2 = util.df(list(dfs1.contract))\n",
    "        dfs3 = pd.concat([dfs2.symbol, dfs1.position.reset_index(drop=True)], axis=1)\n",
    "        dfs4 = dfs3.set_index('symbol').join(df_lu)\n",
    "        dfs5 = dfs4.assign(position = (dfs4.position/dfs4.lot))[['position']]\n",
    "        dfp2 = dfp2.add(dfs5, fill_value=0)  # Add stock positions to option positions\n",
    "\n",
    "    # integrate position and lots and underlyings\n",
    "    dfrq1 = df_lu.join(dfp2)\n",
    "    \n",
    "else:\n",
    "    print('There is nothing in the portfolio')\n",
    "    dfrq1 = df_lu\n",
    "    dfrq1['position'] = 0\n",
    "\n",
    "# fill in the other columns\n",
    "dfrq1 = dfrq1.assign(position=dfrq1.position.fillna(0)) # fillnas with zero\n",
    "dfrq1 = dfrq1.assign(assVal=dfrq1.position*dfrq1.lot*dfrq1.undPrice)\n",
    "\n",
    "assignment_limit = eval(market+'_assignment_limit')\n",
    "\n",
    "dfrq1 = dfrq1.assign(mgnQty=-(assignment_limit/dfrq1.lot/dfrq1.undPrice))\n",
    "dfrq1 = dfrq1.assign(remq=(dfrq1.position-dfrq1.mgnQty))\n",
    "dfrq = dfrq1.assign(remq=dfrq1.remq.fillna(0))[['remq']]\n",
    "dfrq = dfrq.assign(remq=dfrq.remq.astype('int'))\n",
    "\n",
    "# integrate df_opt with remaining quantity\n",
    "\n",
    "df_opt10 = df_opt9.set_index('symbol').join(dfrq).reset_index()\n",
    "df_opt10 = df_opt10[df_opt10.remq > 0]  # remove options that have busted the remaining quantities\n",
    "\n",
    "df_opt11 = df_opt10[~df_opt10.symbol.isin(blacklist)] # remove blacklists\n",
    "\n",
    "# set the expected price and expected rom\n",
    "df_opt12 = df_opt11.assign(qty=1, \n",
    "                           expPrice=np.maximum( \\\n",
    "                                             np.maximum(minexpRom/df_opt11.RoM*(df_opt11.optPrice+prec), minexpOptPrice), \\\n",
    "                                                      df_opt11.optPrice+prec))\n",
    "df_opt13 = df_opt12.assign(expRom=(df_opt12.expPrice*df_opt12.lot-df_opt12.comm)/df_opt12.margin*365/df_opt12.dte)                       \n",
    "\n",
    "# Re-adjust expPrice for expRom < minexpRom. \n",
    "# Re-calculate expRom.\n",
    "# This adjustment is for optPrice = 0 and negative margin options.\n",
    "mask = df_opt13.expRom < minexpRom\n",
    "\n",
    "df_opt13[mask] = df_opt13[mask].assign(expPrice=minexpRom/df_opt13[mask].expRom*df_opt13[mask].expPrice)\n",
    "\n",
    "df_opt13 = df_opt13.replace([np.inf, -np.inf], np.nan).dropna() # remove infinities\n",
    "mask = df_opt13.expRom < minexpRom # to correct the length of the df\n",
    "\n",
    "df_opt13 = df_opt13.assign(expPrice=[get_prec(p, prec) for p in df_opt13.expPrice])\n",
    "df_opt13[mask] = df_opt13[mask].assign(expRom=(df_opt13[mask].expPrice*df_opt13[mask].lot-df_opt13[mask].comm)/df_opt13[mask].margin*365/df_opt13[mask].dte)\n",
    "\n",
    "# symbols busting remaining quantity limit\n",
    "d = {'qty': 'sumOrdQty', 'remq': 'remq'}\n",
    "df_bustingrq = df_opt13.groupby('symbol').agg({'qty': 'sum', 'remq': 'mean'}).rename(columns=d)\n",
    "df_bustingrq = df_bustingrq[df_bustingrq.sumOrdQty > df_bustingrq.remq].reset_index()\n",
    "\n",
    "df_bustingrq.assign(delta=df_bustingrq.remq.sub(df_bustingrq.sumOrdQty, axis=0)).sort_values('delta')\n",
    "\n",
    "df_opt13.to_pickle(fspath+'targets.pkl')\n",
    "\n",
    "df_targets = pd.read_pickle(fspath+'targets.pkl').reset_index(drop=True)\n",
    "\n",
    "print(\"\\nCompleted creating the targets\\n\")\n",
    "\n",
    "#... Get buys from existing open trades\n",
    "df_buys = get_df_buys(ib, market, prec)\n",
    "\n",
    "df_buys.to_pickle(fspath+'closing_buys.pkl')\n",
    "\n",
    "print('\\nCompleted Generating BUYs to close\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... Get buys from existing open trades\n",
    "df_buys = get_df_buys(ib, market, prec)\n",
    "df_buys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_buys = pd.read_pickle(fspath+'closing_buys.pkl')\n",
    "# df_targets = pd.read_pickle(fspath+'targets.pkl').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# !!!***  WARNING ***!!! THIS CODE PLACES BUY (HARVEST) TRADES\n",
    "buy_tb = buys(ib, df_buys, exchange)\n",
    "buy_trades = doTrades(ib, buy_tb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# !!!*** WARNING ***!!! THIS CODE PLACES SELL TRADES\n",
    "\n",
    "# get targets\n",
    "df_targets = pd.read_pickle(fspath+'targets.pkl').reset_index(drop=True)\n",
    "\n",
    "# build the trading blocks\n",
    "sell_tb = sells(ib, df_targets, exchange)\n",
    "\n",
    "# sell the trading blocks\n",
    "sell_trades = doTrades(ib, sell_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pivottablejs import pivot_ui\n",
    "from IPython.core.display import HTML\n",
    "pivot_ui(df_targets,outfile_path=\"pivottablejs.html\")\n",
    "HTML(\"pivottablejs.html\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# !!!! *** THIS CANCELS ALL TRADES !!!!\n",
    "ib.reqGlobalCancel()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ERROR RECTIFICATION FOR DOUBLE BUYS. BUY WILL BE AT MARKET PRICE !!!\n",
    "# Revers trades for double BUYs - made by mistake.\n",
    "df_error = dfp1[(dfp1.position > 0) & (dfp1.secType == 'OPT')]\n",
    "df_error = df_error.assign(qty = df_error.position, optId = df_error.conId)\n",
    "error_tb = tb_market_price(ib, df_error, 'SELL', exchange)\n",
    "\n",
    "## error_trades = doTrades(ib, error_tb) # uncomment to place the trades"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DELETE ALL DATA IN FOLDERS for SNP !!!\n",
    "folderpaths = [\"../data/snp/\", \"../data/log/\"]\n",
    "\n",
    "for folder in folderpaths:\n",
    "    for files in listdir(folder):\n",
    "        file_path = path.join(folder, files)\n",
    "        try:\n",
    "            if path.isfile(file_path):\n",
    "                unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
