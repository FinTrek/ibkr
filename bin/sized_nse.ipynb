{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualifying option contracts ...(2 to 8 mins)\n",
      "IBKR margins for  AMBUJACEM19JUL270CE   : 100%|████████████████████████████████| 50/50 [00:42<00:00,  1.28 symexpiry/s]\n",
      "IBKR margins for  ASIANPAINT19AUG1020PE : 100%|████████████████████████████████| 50/50 [00:26<00:00,  1.30 symexpiry/s]\n",
      "IBKR margins for  BAJFINANCE19AUG4600CE : 100%|████████████████████████████████| 50/50 [00:27<00:00,  1.36s/ symexpiry]\n",
      "IBKR margins for  BATAINDIA19JUL1120PE  : 100%|████████████████████████████████| 50/50 [00:17<00:00,  2.73 symexpiry/s]\n",
      "IBKR margins for  BHARTIARTL19AUG410CE  : 100%|████████████████████████████████| 50/50 [00:43<00:00,  2.23 symexpiry/s]\n",
      "IBKR margins for  BSOFT19JUL125CE       : 100%|████████████████████████████████| 50/50 [00:48<00:00,  1.02 symexpiry/s]\n",
      "IBKR margins for  CESC19JUL580PE        : 100%|████████████████████████████████| 50/50 [00:45<00:00,  1.09 symexpiry/s]\n",
      "IBKR margins for  CONCOR19AUG430PE      : 100%|████████████████████████████████| 50/50 [00:49<00:00,  2.52 symexpiry/s]\n",
      "IBKR margins for  DLF19JUL105PE         : 100%|████████████████████████████████| 50/50 [00:37<00:00,  1.16 symexpiry/s]\n",
      "IBKR margins for  ESCORTS19JUL800CE     : 100%|████████████████████████████████| 50/50 [00:40<00:00,  1.23 symexpiry/s]\n",
      "IBKR margins for  GMRINFRA19AUG7PE      : 100%|████████████████████████████████| 50/50 [00:38<00:00,  1.23s/ symexpiry]\n",
      "IBKR margins for  HDFC19AUG2540CE       : 100%|████████████████████████████████| 50/50 [00:32<00:00,  1.14s/ symexpiry]\n",
      "IBKR margins for  HINDUNILVR19JUL2100CE : 100%|████████████████████████████████| 50/50 [00:49<00:00,  1.19s/ symexpiry]\n",
      "IBKR margins for  IDBI19JUL62CE         : 100%|████████████████████████████████| 50/50 [00:32<00:00,  1.53 symexpiry/s]\n",
      "IBKR margins for  INDUSINDBK19AUG1900CE : 100%|████████████████████████████████| 50/50 [00:34<00:00,  1.45 symexpiry/s]\n",
      "IBKR margins for  JSWSTEEL19JUL175PE    : 100%|████████████████████████████████| 50/50 [00:31<00:00,  1.60 symexpiry/s]\n",
      "IBKR margins for  LT19JUL1320PE         : 100%|████████████████████████████████| 50/50 [00:48<00:00,  1.02 symexpiry/s]\n",
      "IBKR margins for  MCDOWELL-N19JUL770CE  : 100%|████████████████████████████████| 50/50 [00:29<00:00,  3.91 symexpiry/s]\n",
      "IBKR margins for  M&M19JUL760CE         : 100%|████████████████████████████████| 50/50 [01:02<00:00,  2.65 symexpiry/s]\n",
      "IBKR margins for  NATIONALUM19AUG70CE   : 100%|████████████████████████████████| 50/50 [00:48<00:00,  1.04 symexpiry/s]\n",
      "IBKR margins for  NIFTY1980813000CE     : 100%|████████████████████████████████| 50/50 [00:25<00:00,  2.17 symexpiry/s]\n",
      "IBKR margins for  OFSS19AUG4000CE       : 100%|████████████████████████████████| 50/50 [00:33<00:00,  2.72 symexpiry/s]\n",
      "IBKR margins for  PETRONET19AUG285CE    : 100%|████████████████████████████████| 50/50 [00:31<00:00,  2.93 symexpiry/s]\n",
      "IBKR margins for  PVR19AUG2140CE        : 100%|████████████████████████████████| 50/50 [00:38<00:00,  1.71s/ symexpiry]\n",
      "IBKR margins for  RELIANCE19JUL980PE    : 100%|████████████████████████████████| 50/50 [00:38<00:00,  5.65 symexpiry/s]\n",
      "IBKR margins for  SRF19JUL3700CE        : 100%|████████████████████████████████| 50/50 [00:56<00:00,  1.21s/ symexpiry]\n",
      "IBKR margins for  TATACHEM19JUL740CE    : 100%|████████████████████████████████| 50/50 [00:34<00:00,  1.12 symexpiry/s]\n",
      "IBKR margins for  TATAPOWER19AUG90CE    : 100%|████████████████████████████████| 50/50 [00:08<00:00,  1.14 symexpiry/s]\n",
      "IBKR margins for  TORNTPOWER19JUL305CE  : 100%|████████████████████████████████| 50/50 [00:31<00:00,  4.04 symexpiry/s]\n",
      "IBKR margins for  UNIONBANK19AUG110CE   : 100%|████████████████████████████████| 50/50 [00:43<00:00,  1.99 symexpiry/s]\n",
      "IBKR margins for  ZEEL19JUL560CE        : 100%|████████████████████████████████| 50/50 [00:22<00:00,  2.22 symexpiry/s]\n",
      "IBKR margins for  ZEEL19AUG540CE        : 100%|██████████████████████████████████| 4/4 [00:03<00:00,  1.18 symexpiry/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Program to down-size option chains\n",
    "Date: 24-June-2019\n",
    "Rev: 1.0\n",
    "Time taken to execute fully: 1 hour and 15 mins\"\"\"\n",
    "\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "# # from json\n",
    "a = assign_var('common') + assign_var('nse')\n",
    "for v in a:\n",
    "    exec(v)\n",
    "\n",
    "\n",
    "# ib = get_connected('nse', 'live')\n",
    "df_chains = pd.read_pickle(fspath+'nse_chains.pkl')\n",
    "df_ohlcs = pd.read_pickle(fspath+'ohlcs.pkl')\n",
    "\n",
    "# log to size_chains.log\n",
    "with open(logpath+'size_chains.log', 'w'):\n",
    "    pass # clear the run log\n",
    "util.logToFile(logpath+'size_chains.log')\n",
    "\n",
    "#... Remove chains not meeting put and call std filter\n",
    "\n",
    "# get dte and remove those greater than maxdte\n",
    "df_chains = df_chains.assign(dte=df_chains.expiry.apply(get_dte))                    \n",
    "df_chains = df_chains[df_chains.dte <= maxdte]\n",
    "\n",
    "# generate std dataframe\n",
    "df = df_ohlcs[['symbol', 'stDev']]  # lookup dataframe\n",
    "df = df.assign(dte=df.groupby('symbol').cumcount()) # get the cumulative count for location as dte\n",
    "df.set_index(['symbol', 'dte'])\n",
    "\n",
    "df1 = df_chains[['symbol', 'dte']]  # data to be looked at\n",
    "df2 = df1.drop_duplicates()  # remove duplicates\n",
    "\n",
    "df_std = df2.set_index(['symbol', 'dte']).join(df.set_index(['symbol', 'dte']))\n",
    "\n",
    "# join to get std in chains\n",
    "df_chainstd = df_chains.set_index(['symbol', 'dte']).join(df_std).reset_index()\n",
    "\n",
    "# make puts and calls dataframe with std filter\n",
    "df_puts = df_chainstd[df_chainstd.strike < (df_chainstd.undPrice-(df_chainstd.stDev*putstdmult))]\n",
    "df_puts = df_puts.assign(right = 'P')\n",
    "\n",
    "df_calls = df_chainstd[df_chainstd.strike > (df_chainstd.undPrice+(df_chainstd.stDev*callstdmult))]\n",
    "df_calls = df_calls.assign(right = 'C')\n",
    "\n",
    "df_opt = pd.concat([df_puts, df_calls], sort=False).reset_index(drop=True)\n",
    "\n",
    "# get lo52 and hi52\n",
    "df_opt = df_opt.set_index('symbol').join(df_ohlcs.groupby('symbol')\n",
    "                                         .close.agg(['min', 'max'])\n",
    "                                         .rename(columns={'min': 'lo52', 'max': 'hi52'})).reset_index()\n",
    "\n",
    "# make (df and dte) tuple for fallrise\n",
    "tup4fr = [(df_ohlcs[df_ohlcs.symbol == s.symbol], s.dte) \n",
    "          for s in df_opt[['symbol', 'dte']].drop_duplicates().itertuples()]\n",
    "\n",
    "# get the fallrise and put it into a dataframe\n",
    "fr = [fallrise(*t) for t in tup4fr]\n",
    "df_fr = pd.DataFrame(fr, columns=['symbol', 'dte', 'fall', 'rise' ])\n",
    "\n",
    "# merge with df_opt\n",
    "df_opt = pd.merge(df_opt, df_fr, on=['symbol', 'dte'])\n",
    "\n",
    "# make reference strikes from fall_rise\n",
    "df_opt = df_opt.assign(strikeRef = np.where(df_opt.right == 'P', \n",
    "                                            df_opt.undPrice-df_opt.fall, \n",
    "                                            df_opt.undPrice+df_opt.rise))\n",
    "\n",
    "# get the strikes closest to the reference strikes\n",
    "df_opt = df_opt.groupby(['symbol', 'dte']) \\\n",
    "                         .apply(lambda g: g.iloc[abs(g.strike-g.strikeRef) \\\n",
    "                                                 .argsort()[:nBand]])\n",
    "\n",
    "df_opt = df_opt.set_index('symbol').reset_index()\n",
    "\n",
    "# get the option contracts\n",
    "opt_list = [Option(i.symbol, i.expiry, i.strike, i.right, 'NSE') for i in df_opt[['symbol', 'expiry', 'strike', 'right']].itertuples()]\n",
    "\n",
    "util.logToFile(logpath+'test.log') # prevents unknown contract errors in console\n",
    "\n",
    "opt_contracts = []\n",
    "with get_connected('nse', 'live') as ib:\n",
    "    print(\"Qualifying option contracts ...(2 to 8 mins)\")\n",
    "    opt_contracts = ib.qualifyContracts(*opt_list)\n",
    "\n",
    "# integrate optId with df_opt and remove df_opt without optId\n",
    "dfq = util.df(opt_contracts).iloc[:, 1:6]\n",
    "dfq.columns=['optId', 'symbol', 'expiry', 'strike', 'right'] # rename columns\n",
    "df_opt=df_opt.merge(dfq, on=['symbol', 'expiry', 'strike', 'right'], how='left')\n",
    "df_opt = df_opt[~df_opt.optId.isnull()]\n",
    "df_opt = df_opt.assign(optId=df_opt.optId.astype('int'))\n",
    "\n",
    "# get the option prices\n",
    "with get_connected('nse', 'live') as ib:\n",
    "    ticker = ib.reqTickers(*opt_contracts)\n",
    "\n",
    "df_prices = pd.DataFrame({t.contract.conId: {'bid':t.bid, 'ask':t.ask, 'close':t.close} for t in ticker}).T\n",
    "\n",
    "# ...get margins\n",
    "\n",
    "# prepare the lots\n",
    "idlot_idx = df_opt[['optId', 'lot']].set_index('optId').to_dict('index')\n",
    "idlot = {k: Order(action='SELL', orderType='MKT', totalQuantity=v['lot'], whatIf=True) for k, v in idlot_idx.items()}\n",
    "\n",
    "co = [(c, idlot[c.conId]) for c in opt_contracts]\n",
    "\n",
    "# co = co[:110]  # DATA LIMITER !!!\n",
    "coblks = [co[i: i+blk] for i in range(0, len(co), blk)]\n",
    "\n",
    "m = {} # empty dictionary to collect outputs of getMarginAsync\n",
    "with get_connected('nse', 'live') as ib:\n",
    "    async def coro(coblk):\n",
    "        with tqdm(total=len(coblk), file=sys.stdout, unit=' symexpiry') as tqm:\n",
    "            for c, o in coblk:\n",
    "                tqm.set_description(f\"IBKR margins for  {c.localSymbol.ljust(22)}\")\n",
    "                m.update(await getMarginAsync(ib, c, o))\n",
    "                tqm.update(1)\n",
    "            return m\n",
    "\n",
    "# run co-routines to get the margins        \n",
    "for coblk in coblks:\n",
    "    with get_connected('nse', 'live') as ib:\n",
    "        asyncio.run(coro(coblk))\n",
    "\n",
    "# put margins to df_opt\n",
    "m_dict = {i: float(j.initMarginChange) for i, j in {k: v for k, v in m.items() if v}.items() if str(j) != 'nan'}\n",
    "\n",
    "df_margin = pd.DataFrame.from_dict(m_dict, orient='index', columns=['margin'])\n",
    "\n",
    "df_opt = df_opt.set_index('optId').join(df_prices).join(df_margin).reset_index()\n",
    "\n",
    "df_opt = grp_opts(df_opt.assign(rom=df_opt.close/df_opt.margin*365/df_opt.dte*df_opt.lot))\n",
    "\n",
    "df_opt.to_pickle(fspath+'sized.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sized_nse.py\n",
    "from z_helper import *\n",
    "\n",
    "def sized_nse(ib, df_chains, df_ohlcs, market):\n",
    "    ''' Makes a target list of options with rom \n",
    "    based on fallrise and standard deviation\n",
    "    Arg:\n",
    "        (ib) as connection object\n",
    "        (df_chains) generated by nse_chains / snp_chains module\n",
    "        (df_ohlcs)  generated by ohlcs module\n",
    "    Returns: None. But pickles output to sized.pkl\n",
    "    '''\n",
    "    \n",
    "    # init variables from json\n",
    "    init_variables(market)\n",
    "\n",
    "    # log to size_chains.log\n",
    "    with open(logpath+'size_chains.log', 'w'):\n",
    "        pass # clear the run log\n",
    "    util.logToFile(logpath+'size_chains.log')\n",
    "       \n",
    "    #... Remove chains not meeting put and call std filter\n",
    "\n",
    "    # get dte and remove those greater than maxdte\n",
    "    df_chains = df_chains.assign(dte=df_chains.expiry.apply(get_dte))                    \n",
    "    df_chains = df_chains[df_chains.dte <= maxdte]\n",
    "\n",
    "    # generate std dataframe\n",
    "    df = df_ohlcs[['symbol', 'stDev']]  # lookup dataframe\n",
    "    df = df.assign(dte=df.groupby('symbol').cumcount()) # get the cumulative count for location as dte\n",
    "    df.set_index(['symbol', 'dte'])\n",
    "\n",
    "    df1 = df_chains[['symbol', 'dte']]  # data to be looked at\n",
    "    df2 = df1.drop_duplicates()  # remove duplicates\n",
    "\n",
    "    df_std = df2.set_index(['symbol', 'dte']).join(df.set_index(['symbol', 'dte']))\n",
    "\n",
    "    # join to get std in chains\n",
    "    df_chainstd = df_chains.set_index(['symbol', 'dte']).join(df_std).reset_index()\n",
    "\n",
    "    # make puts and calls dataframe with std filter\n",
    "    df_puts = df_chainstd[df_chainstd.strike < (df_chainstd.undPrice-(df_chainstd.stDev*putstdmult))]\n",
    "    df_puts = df_puts.assign(right = 'P')\n",
    "\n",
    "    df_calls = df_chainstd[df_chainstd.strike > (df_chainstd.undPrice+(df_chainstd.stDev*callstdmult))]\n",
    "    df_calls = df_calls.assign(right = 'C')\n",
    "\n",
    "    df_opt = pd.concat([df_puts, df_calls], sort=False).reset_index(drop=True)\n",
    "\n",
    "    # get lo52 and hi52\n",
    "    df_opt = df_opt.set_index('symbol').join(df_ohlcs.groupby('symbol')\n",
    "                                         .close.agg(['min', 'max'])\n",
    "                                         .rename(columns={'min': 'lo52', 'max': 'hi52'})).reset_index()\n",
    "\n",
    "    # make (df and dte) tuple for fallrise\n",
    "    tup4fr = [(df_ohlcs[df_ohlcs.symbol == s.symbol], s.dte) \n",
    "          for s in df_opt[['symbol', 'dte']].drop_duplicates().itertuples()]\n",
    "\n",
    "    # get the fallrise and put it into a dataframe\n",
    "    fr = [fallrise(*t) for t in tup4fr]\n",
    "    df_fr = pd.DataFrame(fr, columns=['symbol', 'dte', 'fall', 'rise' ])\n",
    "\n",
    "    # merge with df_opt\n",
    "    df_opt = pd.merge(df_opt, df_fr, on=['symbol', 'dte'])\n",
    "\n",
    "    # make reference strikes from fall_rise\n",
    "    df_opt = df_opt.assign(strikeRef = np.where(df_opt.right == 'P', \n",
    "                                            df_opt.undPrice-df_opt.fall, \n",
    "                                            df_opt.undPrice+df_opt.rise))\n",
    "\n",
    "    # get the strikes closest to the reference strikes\n",
    "    df_opt = df_opt.groupby(['symbol', 'dte']) \\\n",
    "                         .apply(lambda g: g.iloc[abs(g.strike-g.strikeRef) \\\n",
    "                                                 .argsort()[:nBand]])\n",
    "\n",
    "    df_opt = df_opt.set_index('symbol').reset_index()\n",
    "\n",
    "    # get the option contracts\n",
    "    opt_list = [Option(i.symbol, i.expiry, i.strike, i.right, market.upper()) for i in df_opt[['symbol', 'expiry', 'strike', 'right']].itertuples()]\n",
    "\n",
    "    util.logToFile(logpath+'test.log') # prevents unknown contract errors in console\n",
    "\n",
    "    opt_contracts = []\n",
    "    print(\"Qualifying option contracts ...(2 to 8 mins)\")\n",
    "    opt_contracts = ib.qualifyContracts(*opt_list)\n",
    "\n",
    "    # integrate optId with df_opt and remove df_opt without optId\n",
    "    dfq = util.df(opt_contracts).iloc[:, 1:6]\n",
    "    dfq.columns=['optId', 'symbol', 'expiry', 'strike', 'right'] # rename columns\n",
    "    df_opt=df_opt.merge(dfq, on=['symbol', 'expiry', 'strike', 'right'], how='left')\n",
    "    df_opt = df_opt[~df_opt.optId.isnull()]\n",
    "    df_opt = df_opt.assign(optId=df_opt.optId.astype('int'))\n",
    "\n",
    "    # get the option prices\n",
    "    ticker = ib.reqTickers(*opt_contracts)\n",
    "\n",
    "    df_prices = pd.DataFrame({t.contract.conId: {'bid':t.bid, 'ask':t.ask, 'close':t.close} for t in ticker}).T\n",
    "\n",
    "    # ...get margins\n",
    "\n",
    "    # prepare the lots\n",
    "    idlot_idx = df_opt[['optId', 'lot']].set_index('optId').to_dict('index')\n",
    "    idlot = {k: Order(action='SELL', orderType='MKT', totalQuantity=v['lot'], whatIf=True) for k, v in idlot_idx.items()}\n",
    "\n",
    "    co = [(c, idlot[c.conId]) for c in opt_contracts]\n",
    "\n",
    "    # co = co[:110]  # DATA LIMITER !!!\n",
    "    coblks = [co[i: i+blk] for i in range(0, len(co), blk)]\n",
    "\n",
    "    m = {} # empty dictionary to collect outputs of getMarginAsync\n",
    "    async def coro(coblk):\n",
    "        with tqdm(total=len(coblk), file=sys.stdout, unit=' symexpiry') as tqm:\n",
    "            for c, o in coblk:\n",
    "                tqm.set_description(f\"IBKR margins for  {c.localSymbol.ljust(22)}\")\n",
    "                m.update(await getMarginAsync(ib, c, o))\n",
    "                tqm.update(1)\n",
    "            return m\n",
    "\n",
    "    # run co-routines to get the margins        \n",
    "    for coblk in coblks:\n",
    "        asyncio.run(coro(coblk))\n",
    "\n",
    "    # put margins to df_opt\n",
    "    m_dict = {i: float(j.initMarginChange) for i, j in {k: v for k, v in m.items() if v}.items() if str(j) != 'nan'}\n",
    "\n",
    "    df_margin = pd.DataFrame.from_dict(m_dict, orient='index', columns=['margin'])\n",
    "\n",
    "    df_opt = df_opt.set_index('optId').join(df_Sprices).join(df_margin).reset_index()\n",
    "\n",
    "    df_opt = grp_opts(df_opt.assign(rom=df_opt.close/df_opt.margin*365/df_opt.dte*df_opt.lot))\n",
    "\n",
    "    df_opt.to_pickle(fspath+'sized.pkl')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code for NSE sized\n",
    "\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "# from json (for logpath)\n",
    "a = assign_var('nse')\n",
    "for v in a:\n",
    "    exec(v)\n",
    "\n",
    "from chains_nse import *\n",
    "from ohlcs import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #... check for nse_chains.pkl\n",
    "    if path.isfile(fspath+'nse_chains.pkl'):\n",
    "        df_chains = pd.read_pickle(fspath+'nse_chains.pkl')\n",
    "    else:\n",
    "        df_chains = get_chains(nseweb=False)  # get nse purely from a list. Not from nse website\n",
    "\n",
    "#     df_chains = df_chains[df_chains.symbol.isin(['BANKNIFTY', 'PNB'])]  # DATA LIMITER!!!\n",
    "\n",
    "    if path.isfile(fspath+'ohlcs.pkl'):\n",
    "        df_ohlcs = pd.read_pickle(fspath+'ohlcs.pkl')\n",
    "        \n",
    "    else:\n",
    "        id_sym = df_chains.set_index('undId').symbol.to_dict()\n",
    "    \n",
    "    with get_connected('nse', 'live') as ib:\n",
    "        df_ohlcs = ohlcs(ib, id_sym, fspath, logpath)\n",
    "\n",
    "    df_ohlcs.to_pickle(fspath+'ohlcs.pkl')\n",
    "    \n",
    "    market = 'nse'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sized_nse import \n",
    "with get_connected('nse', 'live') as ib:\n",
    "    df_opt = sized_nse(ib, df_chains, df_ohlcs, market=market)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sized_nse import *\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "market = 'nse'\n",
    "\n",
    "init_variables(market)\n",
    "\n",
    "# # # from json\n",
    "# a = assign_var('common') + assign_var(market)\n",
    "# for v in a:\n",
    "#     exec(v)\n",
    "\n",
    "df_chains = pd.read_pickle(fspath+market+'_chains.pkl')\n",
    "df_ohlcs = pd.read_pickle(fspath+'ohlcs.pkl')\n",
    "\n",
    "with get_connected('nse', 'live') as ib:\n",
    "    df_opt = sized_nse(ib, df_chains, df_ohlcs, market='nse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z_helper import *\n",
    "market = 'nse'\n",
    "\n",
    "x = init_variables(market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec('global '+x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# test code for NSE\n",
    "\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "# from json (for logpath)\n",
    "a = assign_var('nse')\n",
    "for v in a:\n",
    "    exec(v)\n",
    "\n",
    "from chains_nse import *\n",
    "from ohlcs import *\n",
    "from sized import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #... check for nse_chains.pkl\n",
    "    if path.isfile(fspath+'nse_chains.pkl'):\n",
    "        df_chains = pd.read_pickle(fspath+'nse_chains.pkl')\n",
    "    else:\n",
    "        df_chains = get_chains(nseweb=False)  # get nse purely from a list. Not from nse website\n",
    "\n",
    "#     df_chains = df_chains[df_chains.symbol.isin(['BANKNIFTY', 'PNB'])]  # DATA LIMITER!!!\n",
    "\n",
    "    id_sym = df_chains.set_index('undId').symbol.to_dict()\n",
    "\n",
    "    if path.isfile(fspath+'ohlcs.pkl'):\n",
    "        df_ohlcs = pd.read_pickle(fspath+'ohlcs.pkl')\n",
    "    else:\n",
    "        with get_connected('nse', 'live') as ib:\n",
    "            df_ohlcs = ohlcs(ib, id_sym, fspath, logpath)\n",
    "\n",
    "    #... run size_chains\n",
    "    with get_connected('nse', 'live') as ib:\n",
    "        df_target = sized_nse(ib, df_chains=df_chains, df_ohlcs=df_ohlcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_target\n",
    "for v in a:\n",
    "    exec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = 'nse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = assign_var('common') + assign_var(market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in a:\n",
    "    exec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_connected('nse', 'live') as ib:\n",
    "    size_chains(ib, df_chains, df_ohlcs, market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt[mask].sort_values('rom', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'nse'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
