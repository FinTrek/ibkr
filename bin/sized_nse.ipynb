{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Program to down-size option chains\n",
    "Date: 24-June-2019\n",
    "Rev: 1.0\n",
    "Time taken to execute fully: 1 hour and 15 mins\"\"\"\n",
    "\n",
    "from z_helper import *\n",
    "\n",
    "# from json\n",
    "a = assign_var('common') + assign_var('nse')\n",
    "for v in a:\n",
    "    exec(v)\n",
    "\n",
    "util.startLoop()\n",
    "# ib = get_connected('nse', 'live')\n",
    "df_chains = pd.read_pickle(fspath+'nse_chains.pkl')\n",
    "df_ohlcs = pd.read_pickle(fspath+'ohlcs.pkl')\n",
    "\n",
    "# log to size_chains.log\n",
    "with open(logpath+'size_chains.log', 'w'):\n",
    "    pass # clear the run log\n",
    "util.logToFile(logpath+'size_chains.log')\n",
    "\n",
    "#... Remove chains not meeting put and call std filter\n",
    "\n",
    "# get dte and remove those greater than maxdte\n",
    "df_chains = df_chains.assign(dte=df_chains.expiry.apply(get_dte))                    \n",
    "df_chains = df_chains[df_chains.dte <= maxdte]\n",
    "\n",
    "# generate std dataframe\n",
    "df = df_ohlcs[['symbol', 'stDev']]  # lookup dataframe\n",
    "df = df.assign(dte=df.groupby('symbol').cumcount()) # get the cumulative count for location as dte\n",
    "df.set_index(['symbol', 'dte'])\n",
    "\n",
    "df1 = df_chains[['symbol', 'dte']]  # data to be looked at\n",
    "df2 = df1.drop_duplicates()  # remove duplicates\n",
    "\n",
    "df_std = df2.set_index(['symbol', 'dte']).join(df.set_index(['symbol', 'dte']))\n",
    "\n",
    "# join to get std in chains\n",
    "df_chainstd = df_chains.set_index(['symbol', 'dte']).join(df_std).reset_index()\n",
    "\n",
    "# make puts and calls dataframe with std filter\n",
    "df_puts = df_chainstd[df_chainstd.strike < (df_chainstd.undPrice-(df_chainstd.stDev*putstdmult))]\n",
    "df_puts = df_puts.assign(right = 'P')\n",
    "\n",
    "df_calls = df_chainstd[df_chainstd.strike > (df_chainstd.undPrice+(df_chainstd.stDev*callstdmult))]\n",
    "df_calls = df_calls.assign(right = 'C')\n",
    "\n",
    "df_opt = pd.concat([df_puts, df_calls], sort=False).reset_index(drop=True)\n",
    "\n",
    "# get lo52 and hi52\n",
    "df_opt = df_opt.set_index('symbol').join(df_ohlcs.groupby('symbol')\n",
    "                                         .close.agg(['min', 'max'])\n",
    "                                         .rename(columns={'min': 'lo52', 'max': 'hi52'})).reset_index()\n",
    "\n",
    "# make (df and dte) tuple for fallrise\n",
    "tup4fr = [(df_ohlcs[df_ohlcs.symbol == s.symbol], s.dte) \n",
    "          for s in df_opt[['symbol', 'dte']].drop_duplicates().itertuples()]\n",
    "\n",
    "# get the fallrise and put it into a dataframe\n",
    "fr = [fallrise(*t) for t in tup4fr]\n",
    "df_fr = pd.DataFrame(fr, columns=['symbol', 'dte', 'fall', 'rise' ])\n",
    "\n",
    "# merge with df_opt\n",
    "df_opt = pd.merge(df_opt, df_fr, on=['symbol', 'dte'])\n",
    "\n",
    "# make reference strikes from fall_rise\n",
    "df_opt = df_opt.assign(strikeRef = np.where(df_opt.right == 'P', \n",
    "                                            df_opt.undPrice-df_opt.fall, \n",
    "                                            df_opt.undPrice+df_opt.rise))\n",
    "\n",
    "# get the strikes closest to the reference strikes\n",
    "df_opt = df_opt.groupby(['symbol', 'dte']) \\\n",
    "                         .apply(lambda g: g.iloc[abs(g.strike-g.strikeRef) \\\n",
    "                                                 .argsort()[:nBand]])\n",
    "\n",
    "df_opt = df_opt.set_index('symbol').reset_index()\n",
    "\n",
    "# get the option contracts\n",
    "opt_list = [Option(i.symbol, i.expiry, i.strike, i.right, 'NSE') for i in df_opt[['symbol', 'expiry', 'strike', 'right']].itertuples()]\n",
    "\n",
    "util.logToFile(logpath+'test.log') # prevents unknown contract errors in console\n",
    "\n",
    "opt_contracts = []\n",
    "with get_connected('nse', 'live') as ib:\n",
    "    print(\"Qualifying option contracts ...(2 to 8 mins)\")\n",
    "    opt_contracts = ib.qualifyContracts(*opt_list)\n",
    "\n",
    "# integrate optId with df_opt and remove df_opt without optId\n",
    "dfq = util.df(opt_contracts).iloc[:, 1:6]\n",
    "dfq.columns=['optId', 'symbol', 'expiry', 'strike', 'right'] # rename columns\n",
    "df_opt=df_opt.merge(dfq, on=['symbol', 'expiry', 'strike', 'right'], how='left')\n",
    "df_opt = df_opt[~df_opt.optId.isnull()]\n",
    "df_opt = df_opt.assign(optId=df_opt.optId.astype('int'))\n",
    "\n",
    "# get the option prices\n",
    "with get_connected('nse', 'live') as ib:\n",
    "    ticker = ib.reqTickers(*opt_contracts)\n",
    "\n",
    "df_prices = pd.DataFrame({t.contract.conId: {'bid':t.bid, 'ask':t.ask, 'close':t.close} for t in ticker}).T\n",
    "\n",
    "# ...get margins\n",
    "\n",
    "# prepare the lots\n",
    "idlot_idx = df_opt[['optId', 'lot']].set_index('optId').to_dict('index')\n",
    "idlot = {k: Order(action='SELL', orderType='MKT', totalQuantity=v['lot'], whatIf=True) for k, v in idlot_idx.items()}\n",
    "\n",
    "co = [(c, idlot[c.conId]) for c in opt_contracts]\n",
    "\n",
    "# co = co[:110]  # DATA LIMITER !!!\n",
    "coblks = [co[i: i+blk] for i in range(0, len(co), blk)]\n",
    "\n",
    "m = {} # empty dictionary to collect outputs of getMarginAsync\n",
    "with get_connected('nse', 'live') as ib:\n",
    "    async def coro(coblk):\n",
    "        with tqdm(total=len(coblk), file=sys.stdout, unit=' symexpiry') as tqm:\n",
    "            for c, o in coblk:\n",
    "                tqm.set_description(f\"IBKR margins for  {c.localSymbol.ljust(22)}\")\n",
    "                m.update(await getMarginAsync(ib, c, o))\n",
    "                tqm.update(1)\n",
    "            return m\n",
    "\n",
    "# run co-routines to get the margins        \n",
    "for coblk in coblks:\n",
    "    with get_connected('nse', 'live') as ib:\n",
    "        asyncio.run(coro(coblk))\n",
    "\n",
    "# put margins to df_opt\n",
    "m_dict = {i: float(j.initMarginChange) for i, j in {k: v for k, v in m.items() if v}.items() if str(j) != 'nan'}\n",
    "\n",
    "df_margin = pd.DataFrame.from_dict(m_dict, orient='index', columns=['margin'])\n",
    "\n",
    "df_opt = df_opt.set_index('optId').join(df_prices).join(df_margin).reset_index()\n",
    "\n",
    "df_opt = grp_opts(df_opt.assign(rom=df_opt.close/df_opt.margin*365/df_opt.dte*df_opt.lot))\n",
    "\n",
    "df_opt.to_pickle(fspath+'sized.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sized_nse.py\n",
    "from z_helper import *\n",
    "\n",
    "def sized_nse(ib, df_chains, df_ohlcs, market):\n",
    "    ''' Makes a target list of options with rom \n",
    "    based on fallrise and standard deviation\n",
    "    Arg:\n",
    "        (ib) as connection object\n",
    "        (df_chains) generated by nse_chains / snp_chains module\n",
    "        (df_ohlcs)  generated by ohlcs module\n",
    "    Returns: None. But pickles output to sized.pkl\n",
    "    '''\n",
    "    \n",
    "    # init variables from json\n",
    "    init_variables(market)\n",
    "\n",
    "    # log to size_chains.log\n",
    "    with open(logpath+'size_chains.log', 'w'):\n",
    "        pass # clear the run log\n",
    "    util.logToFile(logpath+'size_chains.log')\n",
    "       \n",
    "    #... Remove chains not meeting put and call std filter\n",
    "\n",
    "    # get dte and remove those greater than maxdte\n",
    "    df_chains = df_chains.assign(dte=df_chains.expiry.apply(get_dte))                    \n",
    "    df_chains = df_chains[df_chains.dte <= maxdte]\n",
    "\n",
    "    # generate std dataframe\n",
    "    df = df_ohlcs[['symbol', 'stDev']]  # lookup dataframe\n",
    "    df = df.assign(dte=df.groupby('symbol').cumcount()) # get the cumulative count for location as dte\n",
    "    df.set_index(['symbol', 'dte'])\n",
    "\n",
    "    df1 = df_chains[['symbol', 'dte']]  # data to be looked at\n",
    "    df2 = df1.drop_duplicates()  # remove duplicates\n",
    "\n",
    "    df_std = df2.set_index(['symbol', 'dte']).join(df.set_index(['symbol', 'dte']))\n",
    "\n",
    "    # join to get std in chains\n",
    "    df_chainstd = df_chains.set_index(['symbol', 'dte']).join(df_std).reset_index()\n",
    "\n",
    "    # make puts and calls dataframe with std filter\n",
    "    df_puts = df_chainstd[df_chainstd.strike < (df_chainstd.undPrice-(df_chainstd.stDev*putstdmult))]\n",
    "    df_puts = df_puts.assign(right = 'P')\n",
    "\n",
    "    df_calls = df_chainstd[df_chainstd.strike > (df_chainstd.undPrice+(df_chainstd.stDev*callstdmult))]\n",
    "    df_calls = df_calls.assign(right = 'C')\n",
    "\n",
    "    df_opt = pd.concat([df_puts, df_calls], sort=False).reset_index(drop=True)\n",
    "\n",
    "    # get lo52 and hi52\n",
    "    df_opt = df_opt.set_index('symbol').join(df_ohlcs.groupby('symbol')\n",
    "                                         .close.agg(['min', 'max'])\n",
    "                                         .rename(columns={'min': 'lo52', 'max': 'hi52'})).reset_index()\n",
    "\n",
    "    # make (df and dte) tuple for fallrise\n",
    "    tup4fr = [(df_ohlcs[df_ohlcs.symbol == s.symbol], s.dte) \n",
    "          for s in df_opt[['symbol', 'dte']].drop_duplicates().itertuples()]\n",
    "\n",
    "    # get the fallrise and put it into a dataframe\n",
    "    fr = [fallrise(*t) for t in tup4fr]\n",
    "    df_fr = pd.DataFrame(fr, columns=['symbol', 'dte', 'fall', 'rise' ])\n",
    "\n",
    "    # merge with df_opt\n",
    "    df_opt = pd.merge(df_opt, df_fr, on=['symbol', 'dte'])\n",
    "\n",
    "    # make reference strikes from fall_rise\n",
    "    df_opt = df_opt.assign(strikeRef = np.where(df_opt.right == 'P', \n",
    "                                            df_opt.undPrice-df_opt.fall, \n",
    "                                            df_opt.undPrice+df_opt.rise))\n",
    "\n",
    "    # get the strikes closest to the reference strikes\n",
    "    df_opt = df_opt.groupby(['symbol', 'dte']) \\\n",
    "                         .apply(lambda g: g.iloc[abs(g.strike-g.strikeRef) \\\n",
    "                                                 .argsort()[:nBand]])\n",
    "\n",
    "    df_opt = df_opt.set_index('symbol').reset_index()\n",
    "\n",
    "    # get the option contracts\n",
    "    opt_list = [Option(i.symbol, i.expiry, i.strike, i.right, market.upper()) for i in df_opt[['symbol', 'expiry', 'strike', 'right']].itertuples()]\n",
    "\n",
    "    util.logToFile(logpath+'test.log') # prevents unknown contract errors in console\n",
    "\n",
    "    opt_contracts = []\n",
    "    print(\"Qualifying option contracts ...(2 to 8 mins)\")\n",
    "    opt_contracts = ib.qualifyContracts(*opt_list)\n",
    "\n",
    "    # integrate optId with df_opt and remove df_opt without optId\n",
    "    dfq = util.df(opt_contracts).iloc[:, 1:6]\n",
    "    dfq.columns=['optId', 'symbol', 'expiry', 'strike', 'right'] # rename columns\n",
    "    df_opt=df_opt.merge(dfq, on=['symbol', 'expiry', 'strike', 'right'], how='left')\n",
    "    df_opt = df_opt[~df_opt.optId.isnull()]\n",
    "    df_opt = df_opt.assign(optId=df_opt.optId.astype('int'))\n",
    "\n",
    "    # get the option prices\n",
    "    ticker = ib.reqTickers(*opt_contracts)\n",
    "\n",
    "    df_prices = pd.DataFrame({t.contract.conId: {'bid':t.bid, 'ask':t.ask, 'close':t.close} for t in ticker}).T\n",
    "\n",
    "    # ...get margins\n",
    "\n",
    "    # prepare the lots\n",
    "    idlot_idx = df_opt[['optId', 'lot']].set_index('optId').to_dict('index')\n",
    "    idlot = {k: Order(action='SELL', orderType='MKT', totalQuantity=v['lot'], whatIf=True) for k, v in idlot_idx.items()}\n",
    "\n",
    "    co = [(c, idlot[c.conId]) for c in opt_contracts]\n",
    "\n",
    "    # co = co[:110]  # DATA LIMITER !!!\n",
    "    coblks = [co[i: i+blk] for i in range(0, len(co), blk)]\n",
    "\n",
    "    m = {} # empty dictionary to collect outputs of getMarginAsync\n",
    "    async def coro(coblk):\n",
    "        with tqdm(total=len(coblk), file=sys.stdout, unit=' symexpiry') as tqm:\n",
    "            for c, o in coblk:\n",
    "                tqm.set_description(f\"IBKR margins for  {c.localSymbol.ljust(22)}\")\n",
    "                m.update(await getMarginAsync(ib, c, o))\n",
    "                tqm.update(1)\n",
    "            return m\n",
    "\n",
    "    # run co-routines to get the margins        \n",
    "    for coblk in coblks:\n",
    "        asyncio.run(coro(coblk))\n",
    "\n",
    "    # put margins to df_opt\n",
    "    m_dict = {i: float(j.initMarginChange) for i, j in {k: v for k, v in m.items() if v}.items() if str(j) != 'nan'}\n",
    "\n",
    "    df_margin = pd.DataFrame.from_dict(m_dict, orient='index', columns=['margin'])\n",
    "\n",
    "    df_opt = df_opt.set_index('optId').join(df_Sprices).join(df_margin).reset_index()\n",
    "\n",
    "    df_opt = grp_opts(df_opt.assign(rom=df_opt.close/df_opt.margin*365/df_opt.dte*df_opt.lot))\n",
    "\n",
    "    df_opt.to_pickle(fspath+'sized.pkl')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fspath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cdc21ecf9872>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#     exec(v)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdf_chains\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmarket\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_chains.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdf_ohlcs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'ohlcs.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fspath' is not defined"
     ]
    }
   ],
   "source": [
    "from sized_nse import *\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "market = 'nse'\n",
    "\n",
    "init_variables(market)\n",
    "\n",
    "# # # from json\n",
    "# a = assign_var('common') + assign_var(market)\n",
    "# for v in a:\n",
    "#     exec(v)\n",
    "\n",
    "df_chains = pd.read_pickle(fspath+market+'_chains.pkl')\n",
    "df_ohlcs = pd.read_pickle(fspath+'ohlcs.pkl')\n",
    "\n",
    "with get_connected('nse', 'live') as ib:\n",
    "    df_opt = sized_nse(ib, df_chains, df_ohlcs, market='nse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z_helper import *\n",
    "market = 'nse'\n",
    "\n",
    "x = init_variables(market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"c:\\users\\kashir\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3296\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-1188ec03879d>\"\u001b[1;36m, line \u001b[1;32m1\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    exec('global '+x[0])\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<string>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    global blk=50\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "exec('global '+x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# test code for NSE\n",
    "\n",
    "from z_helper import *\n",
    "util.startLoop()\n",
    "\n",
    "# from json (for logpath)\n",
    "a = assign_var('nse')\n",
    "for v in a:\n",
    "    exec(v)\n",
    "\n",
    "from chains_nse import *\n",
    "from ohlcs import *\n",
    "from sized import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #... check for nse_chains.pkl\n",
    "    if path.isfile(fspath+'nse_chains.pkl'):\n",
    "        df_chains = pd.read_pickle(fspath+'nse_chains.pkl')\n",
    "    else:\n",
    "        df_chains = get_chains(nseweb=False)  # get nse purely from a list. Not from nse website\n",
    "\n",
    "#     df_chains = df_chains[df_chains.symbol.isin(['BANKNIFTY', 'PNB'])]  # DATA LIMITER!!!\n",
    "\n",
    "    id_sym = df_chains.set_index('undId').symbol.to_dict()\n",
    "\n",
    "    if path.isfile(fspath+'ohlcs.pkl'):\n",
    "        df_ohlcs = pd.read_pickle(fspath+'ohlcs.pkl')\n",
    "    else:\n",
    "        with get_connected('nse', 'live') as ib:\n",
    "            df_ohlcs = ohlcs(ib, id_sym, fspath, logpath)\n",
    "\n",
    "    #... run size_chains\n",
    "    with get_connected('nse', 'live') as ib:\n",
    "        df_target = sized_nse(ib, df_chains=df_chains, df_ohlcs=df_ohlcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_target\n",
    "for v in a:\n",
    "    exec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = 'nse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = assign_var('common') + assign_var(market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in a:\n",
    "    exec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_connected('nse', 'live') as ib:\n",
    "    size_chains(ib, df_chains, df_ohlcs, market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt[mask].sort_values('rom', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'nse'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
